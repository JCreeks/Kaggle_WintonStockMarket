{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply [Highway Network] on time series financial data\n",
    "\n",
    "Some of following codes were extracted from [[1]].\n",
    "\n",
    "[Highway Network]: https://en.wikipedia.org/wiki/Highway_network\n",
    "[1]: https://github.com/KhaledSharif/winton-stock-market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lasagne.init import Orthogonal, Constant\n",
    "from lasagne.layers import DenseLayer, MergeLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.nonlinearities import softmax, rectify, sigmoid\n",
    "from lasagne.objectives import categorical_crossentropy, binary_crossentropy, squared_error\n",
    "from lasagne.updates import nesterov_momentum, adadelta\n",
    "from matplotlib import pyplot\n",
    "from nolearn.lasagne import NeuralNet, TrainSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplicativeGatingLayer(MergeLayer):\n",
    "    def __init__(self, gate, input1, input2, **kwargs):\n",
    "        incomings = [gate, input1, input2]\n",
    "        super(MultiplicativeGatingLayer, self).__init__(incomings, **kwargs)\n",
    "        assert gate.output_shape == input1.output_shape == input2.output_shape\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        return inputs[0] * inputs[1] + (1 - inputs[0]) * inputs[2]\n",
    "\n",
    "\n",
    "def highway_dense(incoming, Wh=Orthogonal(), bh=Constant(0.0),\n",
    "                  Wt=Orthogonal(), bt=Constant(-4.0),\n",
    "                  nonlinearity=rectify, **kwargs):\n",
    "    num_inputs = int(np.prod(incoming.output_shape[1:]))\n",
    "\n",
    "    l_h = DenseLayer(incoming, num_units=num_inputs, W=Wh, b=bh, nonlinearity=nonlinearity)\n",
    "    l_t = DenseLayer(incoming, num_units=num_inputs, W=Wt, b=bt, nonlinearity=sigmoid)\n",
    "\n",
    "    return MultiplicativeGatingLayer(gate=l_t, input1=l_h, input2=incoming)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage = 25\n",
    "data = pd.read_csv('../input/train.csv', index_col=0, nrows=int((percentage / 100) * 40000))\n",
    "\n",
    "print(\"Working with \", len(data.index), \" tuples.\")\n",
    "\n",
    "np.random.seed(4815)\n",
    "\n",
    "data['Train_Or_Test'] = np.random.rand(len(data.index), 1) >= 0.9\n",
    "data = data.fillna(-1)\n",
    "\n",
    "train_data = data[data['Train_Or_Test'] == False]\n",
    "test_data = data[data['Train_Or_Test'] == True]\n",
    "\n",
    "train_targets = train_data['Ret_PlusOne'].values\n",
    "train_targets = np.array(train_targets).astype(np.float32)\n",
    "test_targets = test_data['Ret_PlusOne'].values\n",
    "test_targets = np.array(test_targets).astype(np.float32)\n",
    "\n",
    "train_weights = train_data['Weight_Daily'].values\n",
    "test_weights = test_data['Weight_Daily'].values\n",
    "\n",
    "data = data.drop(data.columns[range(146, 210)], axis=1)\n",
    "\n",
    "train_data = train_data.drop(train_data.columns[range(146, 210)], axis=1)\n",
    "test_data = test_data.drop(test_data.columns[range(146, 210)], axis=1)\n",
    "\n",
    "scaling_data = data.drop('Train_Or_Test', axis=1)\n",
    "scaling_data = np.array(scaling_data.values).astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(scaling_data)\n",
    "\n",
    "train_data = train_data.drop('Train_Or_Test', axis=1).values\n",
    "train_data = np.array(train_data).astype(np.float32)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = test_data.drop('Train_Or_Test', axis=1).values\n",
    "test_data = np.array(test_data).astype(np.float32)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = train_data.shape[1]\n",
    "epochs = 100\n",
    "\n",
    "hidden_layers = 4\n",
    "hidden_units = 1024\n",
    "dropout_p = 0.5\n",
    "\n",
    "val_auc = np.zeros(epochs)\n",
    "\n",
    "# ==== Defining the neural network shape ====\n",
    "\n",
    "l_in = InputLayer(shape=(None, num_features))\n",
    "l_hidden1 = DenseLayer(l_in, num_units=hidden_units)\n",
    "l_hidden2 = DropoutLayer(l_hidden1, p=dropout_p)\n",
    "l_current = l_hidden2\n",
    "for k in range(hidden_layers - 1):\n",
    "    l_current = highway_dense(l_current)\n",
    "    l_current = DropoutLayer(l_current, p=dropout_p)\n",
    "l_dropout = DropoutLayer(l_current, p=dropout_p)\n",
    "l_out = DenseLayer(l_dropout, num_units=1, nonlinearity=None)\n",
    "\n",
    "# ==== Neural network definition ====\n",
    "\n",
    "net1 = NeuralNet(layers=l_out,\n",
    "                 update=adadelta, update_rho=0.95, update_learning_rate=1.0,\n",
    "                 train_split=TrainSplit(eval_size=0), verbose=0, max_epochs=1, regression=True)\n",
    "\n",
    "# ==== Print out input shape for diagnosis ====\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_targets.shape)\n",
    "\n",
    "# ==== Train it for n iterations and validate on each iteration ====\n",
    "\n",
    "for i in range(epochs):\n",
    "    net1.fit(train_data, train_targets)\n",
    "    pred = net1.predict(test_data)\n",
    "    val_auc[i] = np.mean((test_targets - pred)**2)\n",
    "    print(i + 1, \"\\t\", val_auc[i], \"\\t\", min(val_auc), \"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==== Make of the plot of the validation accuracy per iteration ====\n",
    "\n",
    "pyplot.plot(val_auc, linewidth=2)\n",
    "pyplot.grid()\n",
    "pyplot.title(\"Minimum MSE is \" + str(min(val_auc)))\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.ylabel(\"Validation MSE\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
